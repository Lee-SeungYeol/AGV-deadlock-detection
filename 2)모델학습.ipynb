{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends\n",
    "import torch.backends.cudnn\n",
    "from torch.utils.data import Dataset, DataLoader,WeightedRandomSampler\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from utils.Custom_Dataset import CustomDataset\n",
    "from utils.config import CFG\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from models.RNN import CNNRNN\n",
    "from models.LSTM import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#12 시드 고정\n",
    "seed = 12\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True  # 반복 가능성을 보장\n",
    "torch.backends.cudnn.benchmark = False     # 성능 손해를 감수하고 일관성 유지\n",
    "\n",
    "print(torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu'))\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed )\n",
    "\n",
    "train_data=np.load('./data/image_train.npy')\n",
    "train_labels=np.load('./data/label_train.npy')\n",
    "\n",
    "indices = np.arange(train_data.shape[0]) ## 데이터 무작위 셔플링\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "train_data = train_data[indices]\n",
    "train_labels = train_labels[indices]\n",
    "\n",
    "\n",
    "\n",
    "test_data=np.load('./data/image_valid.npy')\n",
    "test_labels=np.load('./data/label_valid.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습데이터 8:2로 Train data와 Validation data로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=0.8\n",
    "num_data=len(train_data)\n",
    "\n",
    "data_train=train_data[:int(ratio*num_data)]\n",
    "labels_train=train_labels[:int(ratio*num_data)]\n",
    "\n",
    "data_valid=train_data[int(ratio*num_data):]\n",
    "label_valid=train_labels[int(ratio*num_data):]\n",
    "\n",
    "print(\"Train_data: \", data_train.shape)\n",
    "print(\"Train_label: \", labels_train.shape)\n",
    "\n",
    "print(\"Valid_data: \", data_valid.shape)\n",
    "print(\"Valid_label: \", label_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 Downsampling\n",
    "\n",
    "데드락 데이터를 다운샘플링하여 노말 데이터와 비슷한 데이터 수 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list=[]\n",
    "labels_list=[]\n",
    "count=[0,0]\n",
    "for idx,l in enumerate(labels_train):\n",
    "    if l==1 and count[l]>237:\n",
    "        continue\n",
    "        \n",
    "    if count[l]<238:\n",
    "\n",
    "        count[l]+=1\n",
    "        image_list.append(train_data[idx])\n",
    "        labels_list.append(train_labels[idx])\n",
    "data_train=np.array(image_list)\n",
    "\n",
    "labels_train=np.array(labels_list)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#데이터셋\n",
    "\n",
    "전처리\n",
    "+ RandomTranslate\n",
    "\n",
    "    랜덤하게 이미지 상하좌우 이동 빈 여백 255로 채움\n",
    "+ RandRotateView\n",
    "\n",
    "    -30도에서 +30도로 랜덤하게 이미지 회전(사용)\n",
    "+ RandBrightness\n",
    "\n",
    "    랜덤하게 이미지의 밝기 변경\n",
    "+ RandCutout\n",
    "\n",
    "    랜덤하게 이미지에 구멍 6개 생성 구멍의 크기는 32x32\n",
    "+ RandRotate90\n",
    "\n",
    "    랜덤하게 이미지를 90도, 180도, 270도, 360도 회전\n",
    "+ RandHorizontalFlip\n",
    "    \n",
    "    랜덤하게 이미지를 좌우반전(사용)\n",
    "+ RandVerticalFlip\n",
    "\n",
    "    랜덤하게 이미지를 수직 반전\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset=CustomDataset(data_train,labels_train,mode='Train')\n",
    "valid_dataset=CustomDataset(data_valid,label_valid,mode='Valid')\n",
    "test_dataset=CustomDataset(test_data,test_labels,mode='Valid')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=20\n",
    "t_image=train_dataset.__getitem__(n)[0]\n",
    "t_label=train_dataset.__getitem__(n)[1]\n",
    "print(t_image.shape)\n",
    "print(t_label)\n",
    "print(len(t_image))\n",
    "figure,axis = plt.subplots(5,5,figsize=(12,12))\n",
    "\n",
    "for i,ax in enumerate(axis.flat):\n",
    "    \n",
    "    Img_Pick = t_image[i]\n",
    "    \n",
    "    ax.set_xlabel(Img_Pick.shape)\n",
    "    ax.imshow(Img_Pick.permute(1,2,0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, valid_loader,dataset,criterion, device='cpu'):\n",
    "    \n",
    "    model.eval() \n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valid_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "           \n",
    "            \n",
    "           \n",
    "            outputs,_ = model(images)\n",
    "            \n",
    "\n",
    "            loss = criterion(outputs, labels) \n",
    "            \n",
    "            total_loss += loss\n",
    "            \n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "           \n",
    "            \n",
    "            \n",
    "           \n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    print('outputs: ',predicted)\n",
    "    print('label: ',labels)\n",
    "    print(\"맞춘개수: \",correct_predictions,'/'+str(len(dataset)))\n",
    "    avg_loss = total_loss / len(valid_loader) \n",
    "    accuracy = correct_predictions / len(dataset) \n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate Shceduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmUpRestarts(lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr) * self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (\n",
    "                        1 + math.cos(math.pi * (self.T_cur - self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "\n",
    "        self.eta_max = self.base_eta_max * (self.gamma ** self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"SEED: \",seed)\n",
    "\n",
    "base_net = CNNLSTM().to(CFG['device'])\n",
    "optimizer=torch.optim.Adam(base_net.parameters(),lr=0,betas=(0.5, 0.999), amsgrad=True,weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_accuracy = 0.0\n",
    "sheduler=CosineAnnealingWarmUpRestarts(optimizer,T_0=10,T_mult=1,eta_max=0.001,T_up=3,gamma=0.5)\n",
    "\n",
    "loss_count=0\n",
    "test_accuracy_list=[]\n",
    "for epoch in range(1,CFG['EPOCH']+1):\n",
    "\n",
    "    base_net.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i,(image,label) in enumerate(tqdm(train_dataloader)):\n",
    "        images=image.to(CFG['device'])\n",
    "        labels=label.to(CFG['device']).long()\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs,_ = base_net(images)\n",
    "\n",
    "\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss  # 배치 손실 누적\n",
    "        \n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "        \n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions/len(train_dataset)\n",
    "    \n",
    "    avg_valid_loss, valid_accuracy = evaluate_model(base_net, valid_dataloader, valid_dataset,criterion, CFG['device'])\n",
    "    sheduler.step()\n",
    "    curve_lr=optimizer.param_groups[0]['lr']\n",
    "    print(f'Epoch: {epoch} LEARNING RATE: ',{curve_lr})\n",
    "    print(f'Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Validation Loss: {avg_valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.4f}')\n",
    "    print('COUNT: ',loss_count)\n",
    "    \n",
    "    \n",
    "    torch.save(base_net, './models/'+str(epoch)+'_LSTM_'+str(valid_accuracy)[:5]+'_best_model.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AGV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
