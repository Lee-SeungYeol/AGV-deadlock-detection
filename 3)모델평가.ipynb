{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\AGV\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\user\\anaconda3\\envs\\AGV\\lib\\site-packages\\seaborn\\_statistics.py:32: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.23.4)\n",
      "  from scipy.stats import gaussian_kde\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1.13.1+cu116\n",
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score\n",
    "from tqdm import tqdm\n",
    "from utils.config import CFG\n",
    "from utils.Custom_Dataset import CustomDataset\n",
    "from models.RNN import CNNRNN\n",
    "from models.LSTM import *\n",
    "from sklearn.metrics import (confusion_matrix,recall_score, f1_score)\n",
    "\n",
    "\n",
    "from utils.feature_extraction import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "seed = 4\n",
    "deterministic = True\n",
    "random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "print(torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu'))\n",
    "print(torch.__version__)\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid_data:  (492, 60, 224, 224, 3)\n",
      "Valid_label:  (492,)\n"
     ]
    }
   ],
   "source": [
    "valid_data=np.load('./data/image_valid.npy')\n",
    "valid_labels=np.load('./data/label_valid.npy')\n",
    "print(\"Valid_data: \", valid_data.shape)\n",
    "print(\"Valid_label: \", valid_labels.shape)\n",
    "valid_dataset=CustomDataset(valid_data,valid_labels,mode='Valid')\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, valid_loader, criterion, device='cpu'):\n",
    "    error_batch=[]\n",
    "    error_labels=[]\n",
    "    index=[]\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "    losses=[]\n",
    "    with torch.cuda.amp.autocast():\n",
    "        with torch.no_grad(): \n",
    "            for i,(images, labels) in enumerate(tqdm(valid_loader)):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device).long()\n",
    "            \n",
    "                \n",
    "                outputs,_ = model(images)\n",
    "               \n",
    "                \n",
    "\n",
    "                loss = criterion(outputs, labels) \n",
    "                \n",
    "                total_loss += loss \n",
    "                \n",
    "                predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "              \n",
    "\n",
    "                y_pred.append(predicted.item())\n",
    "                y_true.append(labels.item())\n",
    "                losses.append(outputs)\n",
    "\n",
    "                \n",
    "                \n",
    "                if predicted!=labels:\n",
    "                    error_batch.append(images) # 올바르게 예측하지 못한 이미지 \n",
    "                    error_labels.append(labels)# 올바르게 예측하지 못한 라벨\n",
    "                    index.append(i)# 올바르게 예측하지 못한 인덱스\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "    avg_loss = total_loss / len(valid_loader)  # 평균 손실 계산\n",
    "    accuracy = correct_predictions / len(valid_dataset)  # 정확도 계산\n",
    "    \n",
    "    return avg_loss, accuracy,y_pred,y_true,error_batch,error_labels,index,losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('F:/VSC/opensg/6_LSTM_1.0_best_model.pt').to(CFG['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "test_loss, test_accuracy,y_pred,y_true,error_batch,error_labels,index,losses = evaluate_model(model, valid_dataloader, criterion, CFG['device'])\n",
    "precision = precision_score(y_true, y_pred, pos_label=1)\n",
    "print(f'Precision (정밀도): {precision:.4f}')\n",
    "\n",
    "# Recall (재현율) 계산\n",
    "recall = recall_score(y_true, y_pred, pos_label=1)\n",
    "print(f'Recall (재현율): {recall:.4f}')\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "print(f'F1 스코어: {f1:.4f}')\n",
    "\n",
    "print(f'ACCURACY: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혼동행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Deadlock'], yticklabels=['Normal', 'Deadlock'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ add_image\n",
    "    \n",
    "    영상에서 1초마다 프레임을 Buffer에 저장\n",
    "+ clear_buffer\n",
    "\n",
    "    clear_buffer를 수행시 두번째 이미지 부터 buffer에 저장\n",
    "\n",
    "+ initial_buffer\n",
    "\n",
    "    버퍼를 비우는 함수\n",
    "\n",
    "+ is_ready\n",
    "\n",
    "    buffer의 상태를 확인 buffer의 길이가 sequence_length와 같을때 True를 받음\n",
    "\n",
    "+ buffer_len\n",
    "\n",
    "    buffer의 길이를 반환\n",
    "\n",
    "+ get_sequence\n",
    "\n",
    "    버퍼에 담겨있는 이미지를 CNN-LSTM에 입력하기 위해 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftBuffer:\n",
    "    def __init__(self, sequence_length=60):\n",
    "        \"\"\"\n",
    "        :param sequence_length: 모델에 입력할 시퀀스의 길이 (기본값: 60)\n",
    "        \"\"\"\n",
    "        self.sequence_length = sequence_length\n",
    "        self.buffer = []  # 초기 빈 리스트\n",
    "\n",
    "    def add_image(self, image):\n",
    "        \"\"\"\n",
    "        실시간으로 들어오는 이미지를 버퍼에 추가하며, 기존 프레임을 한 칸씩 앞으로 이동\n",
    "        buffer에 sequence_length보다 더 저게 이미지가 담겨 있을경우 buffer에 이미지 저장\n",
    "        \"\"\"\n",
    "        if len(self.buffer) < self.sequence_length:\n",
    "            self.buffer.append(image)\n",
    "    def clear_buffer(self):\n",
    "        \"\"\"\n",
    "        첫번째 이미지를 제외\n",
    "        \"\"\"\n",
    "        self.buffer = self.buffer[1:]\n",
    "    def initial_buffer(self):\n",
    "        \"\"\"\n",
    "        buffer 비우기\n",
    "        \"\"\"\n",
    "        self.buffer=[]\n",
    "    def is_ready(self):\n",
    "        \"\"\"\n",
    "        buffer에 sequence_length만큼의 이미지가 쌓였는지 확인\n",
    "        \"\"\"\n",
    "        return len(self.buffer) == self.sequence_length\n",
    "    \n",
    "    def buffer_len(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def get_sequence(self):\n",
    "        \"\"\"\n",
    "        buffer에 쌓인 sequence를 반환\n",
    "        :return: torch.Size([sequence_length, 3, H, W]) 형태의 시퀀스 텐서\n",
    "        \"\"\"\n",
    "        return torch.stack(self.buffer).permute(0,3,1,2).unsqueeze(0).to(CFG['device'])\n",
    "\n",
    "buffer = ShiftBuffer(sequence_length=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video_path: 영상주소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#video_path='./raw_data_ng/deadlock-20241015-ng-2.mp4'\n",
    "video_path='./raw_data_normal/deadlock-20241015-normal-2.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) #FPS 계산 현재 동영상 FPS는 30FPS\n",
    "frame_count = 0\n",
    "normal_accuracy='100'\n",
    "deadlock_accuracy='0'\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # 동영상 끝까지 다 읽었을 때 루프 종료\n",
    "\n",
    "    view_frame=cv2.resize(frame,(1320,640)) #시각화 동영상 크기 설정\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "    current_frame_num = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    if frame_count % fps == 0: #1초에 한장씩\n",
    "        frame_resize=cv2.resize(frame,(224,224)) #이미지를 224x224로 조정\n",
    "        frame_resize=torch.from_numpy(frame_resize).float()/255.0 # 255로 나누어주면서 0~1사이로 전처리\n",
    "        buffer.add_image(frame_resize) #버퍼에 이미지 추가\n",
    "        \n",
    "\n",
    "    if buffer.is_ready(): #버퍼에 이미지 개수가 60개일때\n",
    "        \n",
    "        #모델 평가 수행\n",
    "        with torch.no_grad():\n",
    "            output=F.softmax(model(buffer.get_sequence()))\n",
    "            predicted = torch.argmax(output, dim=1)\n",
    "            #평가가 끝나면 버퍼에서 첫번째 이미지를 제거\n",
    "            buffer.clear_buffer()\n",
    "\n",
    "        deadlock_accuracy=str(output[0][1].item()*100)[:5]\n",
    "        normal_accuracy=str(output[0][0].item()*100)[:5]\n",
    "        \n",
    "    cv2.putText(view_frame, \"Normal :\"+normal_accuracy+'%', (1000, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)  # 흰색 글씨\n",
    "\n",
    "    cv2.putText(view_frame, \"DEADLOCK: \"+deadlock_accuracy+'%', (1000, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)  # 빨간 글씨\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('video', view_frame)\n",
    "    \n",
    "    \n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() # 모든 창 닫기\n",
    "buffer.initial_buffer() #버퍼 이미지 모두 제거\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AGV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
